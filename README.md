# Awesome Wikipedia

A curated list of awesome Wikipedia-related frameworks, libraries, software, datasets and references.

- [Awesome Wikipedia](#awesome-wikipedia)
    - [Anti-vandalism](#anti-vandalism)
    - [Statistics](#statistics)
    - [Visualization](#visualization)
    - [Datasets](#datasets)
    - [Frameworks and libraries](#frameworks-and-libraries)
- [Contributing](#contributing)

## Anti-vandalism

* [Huggle](https://github.com/huggle/huggle3-qt-lx) - Semi-automated anti-vandalism tool for Wikipedia.

## Statistics

* [stats.grok.se](https://github.com/abelsson/stats.grok.se) - Page views statistics for several Wikipedia languages. You can select by month and the last 30, 60 or 90 days. It can be exported in JSON.
* [Wikimedia Report Card](https://github.com/wikimedia/limn) - Numbers and graphs for several core metrics (including unique visitors and page views for the entirety of Wikimedia projects), updated monthly.
* [wlm-stats](https://github.com/emijrp/wlm-stats) - Statistics and graphs about the Wiki Loves Monuments photograph contest. It offers metadata files to create your own statistics.
* [wmcharts](https://github.com/emijrp/wmcharts) - A collection of charts about Wikimedia projects, including activity on recent changes, new pages, deletions, blocks, protections, file uploads, reverts and more.

## Visualization

* [Listen to Wikipedia](https://github.com/hatnote/listen-to-wikipedia) - A visual and audio illustration of live editing activity on Wikipedia.
* [wikipulse](https://github.com/edsu/wikipulse) - A real-time view of current edit rates on various major language Wikipedias using node.js. The app connects to Wikimedia IRC chatrooms where page edits are announced by a bot, and keeps track of the edits.
* [wlm-maps](https://tools.wmflabs.org/wlm-maps/) - A map for Wiki Loves Monuments photograph contest. Find monuments nearby you and take some pictures!
* [wmcounter](https://github.com/emijrp/wmcounter) -  A near real-time counter for all Wikimedia projects together.

## Datasets

* [Database dump](http://dumps.wikimedia.org/backup-index.html) - XML dumps for every Wikimedia project. They include metadata and text for every page and edit. Other available datasets are page links, categories, logs, protections and image metadata. Several GB in size.
* [Page views statistics](http://dumps.wikimedia.org/other/pagecounts-raw/) - Hourly zipped files with page views counts for every page.

## Frameworks and libraries

* [MediaWiki Utilities](https://github.com/halfak/Mediawiki-Utilities) - It extracts and process data from MediaWiki installations, slave databases and XML dumps.
* [pywikibot](https://www.mediawiki.org/wiki/Manual:Pywikibot)[:octocat:](https://github.com/wikimedia/pywikibot-core/) - the official companion library for accessing MediaWiki-based websites through API.
* [Wikidata Toolkit](https://github.com/Wikidata/Wikidata-Toolkit) - Open source Java library for using data from Wikidata and other Wikibase sites.
* [WikiData SDK](https://github.com/maxlath/wikidata-sdk) - A JavaScript tool suite to query Wikidata information.

## See also

* [User:Emijrp/All human knowledge](https://en.wikipedia.org/wiki/User:Emijrp/All_human_knowledge) - Estimation of articles needed to cover the sum of all human knowledge.
* [Wikipedia:Statistics](https://en.wikipedia.org/wiki/Wikipedia:Statistics) - Compilation of Wikipedia statistics.
* [Wikipedia:Tools](https://en.wikipedia.org/wiki/Wikipedia:Tools) - Compilation of Wikipedia tools.
* [Wikimedia Tools Labs](http://tools.wmflabs.org) - Hosting and shell for Wikipedia-related tool projects.

# Contributing

For contributing, [open an issue](https://github.com/emijrp/awesome-wikipedia/issues) and/or a [pull request](https://github.com/emijrp/awesome-wikipedia/pulls).
